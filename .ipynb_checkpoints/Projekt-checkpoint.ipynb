{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10b127d2-309d-4214-85ff-226e9852b49a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# BDINF project SS2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a1226f-adc0-4053-ab0c-dda0adedbb8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Topic\n",
    "\n",
    "The main goal is to check if there is a correlation between CO2 emissions and between new/used registered cars in AT (since 200). It would be also good to know how the CO2 emission did reduce over time for newly registered cars as a percentage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4646f297-fd7e-4d35-ad05-7a25ee5a02de",
   "metadata": {
    "tags": []
   },
   "source": [
    "Members: GrÃ©goire Bartek, Matthias Huber, David Berger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1c1535-8d53-4d6d-b8f3-0e885b31e041",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Sources: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8149d648-e033-46fe-9d8b-264c1063f488",
   "metadata": {},
   "source": [
    "Planned Data Source: It is planned to store the data in a MYSQL database. The data from newly registered cars and used regeistered cars will be stored in a seperate tables and the emission data will be stored in a third table, we are currently in the process finding good APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d26bc2-3665-4f75-a766-3f5c72eb1e9d",
   "metadata": {},
   "source": [
    "AT new registered cars: https://www.data.gv.at/katalog/de/dataset/stat_pkw-neuzulassungen-nach-marken-ab-janner-2000#resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a9c5ad-e692-44a0-b62f-53a5469134a9",
   "metadata": {},
   "source": [
    "AT used registered cars: https://www.data.gv.at/katalog/dataset/6fc1c927-bf21-3d72-9333-a9055493ab3c#additional-info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913bfd62-8e7e-454d-9aca-88e8fb8e5c96",
   "metadata": {
    "tags": []
   },
   "source": [
    "emission data: https://www.data.gv.at/katalog/dataset/bd462a04-2453-4c76-95bb-cfbd043540f5#resources (trendbericht nach sektoren)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b367b8-eca6-4795-8eb6-58a672402b4c",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "# Load the data from the CSV file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e186a0-3e20-434a-ab2e-a531b1ed626e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Planned procedure : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9060cf4-196c-4231-a4ec-53066cc67113",
   "metadata": {},
   "source": [
    "MYSQL DB is running in a docker container, which will be versioned in the following Github repository (This is accomplished because we want to save Azure credits):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc50d78-968a-4733-9886-fe7661243e95",
   "metadata": {
    "tags": []
   },
   "source": [
    "https://github.com/huhubi/BDINF_project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe337ca-42b1-4a25-85e1-26a0792ba12e",
   "metadata": {
    "tags": []
   },
   "source": [
    "The queries will be made from this notebook, so the outcome is reproducable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f380bb4-7e26-447d-a401-073750f71201",
   "metadata": {},
   "source": [
    "## Expected Output :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b886311a-2207-42ea-b77b-cbcf5fb7b1fa",
   "metadata": {},
   "source": [
    "The data will be visualized and described in this notebook, it is expected to find a correlation between lower emissions and the production year of cars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccee38f-fd02-45ad-807d-bb52befdb635",
   "metadata": {},
   "source": [
    "# Documentation of procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be4de2f-b530-4366-8ae6-40f904d29a12",
   "metadata": {},
   "source": [
    "First, we are downloading the csv data and doing explorative data analysis from AT emissions to check which categories are fitting for the car data. Since the data is from the years 1990-2022, and the car data is from 2000, just the emissions from 2000 are being considered. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c662a2-9800-4fd7-89e3-6d9b00169414",
   "metadata": {},
   "source": [
    "First, we get the CO2 data from the emissions csv. Here we are looking at the line 33, which has the yearly CO2 data from transport"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c93900d-7d91-435e-b4e6-f71c81ea8217",
   "metadata": {},
   "source": [
    "importing the emissions csv and getting data from 2000-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "baa76132-d0e7-4600-accd-72cc6f902808",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'An error occurred while processing the file: single positional indexer is out-of-bounds'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file paths\n",
    "input_file_path = 'emissions/schadstoffemissionen_1990-2022_nach_trendbericht-sektoren_wide.csv'\n",
    "cleaned_file_path = 'emissions_cleaned.csv'\n",
    "\n",
    "try:\n",
    "    # Since the CSV might be large, we read it in chunks\n",
    "    chunk_list = []  # to hold parts of the file we need\n",
    "    skip_rows = True  # flag to skip rows after finding the desired one\n",
    "\n",
    "    for chunk in pd.read_csv(input_file_path, chunksize=50, encoding='iso-8859-1', on_bad_lines='skip'):\n",
    "        if skip_rows:\n",
    "            # always keep the header\n",
    "            chunk_list.append(chunk.iloc[0])\n",
    "            # Assuming 'CO' is in the second column (index 1), we look for it\n",
    "            if any(chunk.iloc[:, 1].str.contains('CO', na=False)):\n",
    "                # Find the row which contains 'CO'\n",
    "                row = chunk[chunk.iloc[:, 1].str.contains('CO', na=False)].iloc[0]\n",
    "                chunk_list.append(row)\n",
    "                skip_rows = False  # We found the row, no need to keep looking\n",
    "\n",
    "    # Concatenate the filtered rows\n",
    "    filtered_data = pd.concat(chunk_list, axis=1).transpose()\n",
    "\n",
    "    # Save the filtered data to a new CSV file\n",
    "    filtered_data.to_csv(cleaned_file_path, index=False, encoding='utf-8')\n",
    "    success_message = \"Filtered data has been saved to 'emissions_Cleaned.csv'.\"\n",
    "except Exception as e:\n",
    "    success_message = f\"An error occurred while processing the file: {e}\"\n",
    "\n",
    "success_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8aaff4ee-9233-424f-981a-bba3110b9b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Filtered data has been saved to 'emissions_cleaned.csv'.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file paths\n",
    "input_file_path = 'emissions/schadstoffemissionen_1990-2022_nach_trendbericht-sektoren_wide.xslx'\n",
    "cleaned_file_path = 'emissions_cleaned.csv'\n",
    "\n",
    "try:\n",
    "    # Attempt to read the whole file at once\n",
    "    data = pd.read_csv(input_file_path, encoding='iso-8859-1', on_bad_lines='skip')\n",
    "\n",
    "    # Check if we have the expected line 33 after potentially skipping lines\n",
    "    if len(data) >= 33:\n",
    "        # Select the first line (headers) and the 33rd line (data)\n",
    "        filtered_data = data.iloc[[0, 32]]\n",
    "\n",
    "        # Save the filtered data to a new CSV file\n",
    "        filtered_data.to_csv(cleaned_file_path, index=False, encoding='utf-8')\n",
    "        success_message = f\"Filtered data has been saved to '{cleaned_file_path}'.\"\n",
    "    else:\n",
    "        success_message = \"The data does not have 33 lines after skipping bad lines.\"\n",
    "\n",
    "except Exception as e:\n",
    "    success_message = f\"An error occurred: {e}\"\n",
    "\n",
    "success_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699b330d-6c89-4bf9-8ece-2d3c6cd0e529",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
